{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from rtbm import RTBM, minimizer\n",
    "\n",
    "import rtbm.layers as layers\n",
    "import rtbm.model as mdl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from rtbm.costfunctions import mse, crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "MNIST_train = pd.read_csv('~/data/mnist_train.csv', delimiter=\",\",header=None).values\n",
    "MNIST_test  = pd.read_csv('~/data/mnist_test.csv', delimiter=\",\",header=None).values\n",
    "\n",
    "# Prepare data (normalized onto [0,1])\n",
    "Y_train = MNIST_train[0:10000,0]\n",
    "X_train = MNIST_train[0:10000,1:]/255.0\n",
    "\n",
    "Y_test = MNIST_test[:,0]\n",
    "X_test = MNIST_test[:,1:]/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize individual pics\n",
    "i=10\n",
    "print(Y_train[i])\n",
    "I=np.reshape(X_train[i], (28,28))\n",
    "plt.imshow(I, interpolation='nearest',  cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression baseline\n",
    "logreg = linear_model.LogisticRegression(multi_class='multinomial',solver='lbfgs')\n",
    "\n",
    "logreg.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "\n",
    "P=logreg.predict(X_train)\n",
    "\n",
    "print(classification_report(Y_train,P))\n",
    "print(confusion_matrix(Y_train, P))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On test set\n",
    "P=logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test,P))\n",
    "print(confusion_matrix(Y_test, P))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression base line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = linear_model.LinearRegression()\n",
    "\n",
    "linreg.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "\n",
    "P=np.round(linreg.predict(X_train))\n",
    "\n",
    "print(classification_report(Y_train,P))\n",
    "print(confusion_matrix(Y_train, P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On test set\n",
    "P=linreg.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test,P))\n",
    "print(confusion_matrix(Y_test, P))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression via CMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = mdl.Model()\n",
    "M.add(layers.Linear(784,1,paramBound=2))\n",
    "\n",
    "minim = minimizer.CMA(False)\n",
    "sol=minim.train(mse(), M, np.transpose(X_train), np.transpose(Y_train), maxiter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_train)))))\n",
    "\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On test set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_test)))))\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression via SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = mdl.Model()\n",
    "M.add(layers.Linear(784,1))\n",
    "\n",
    "minim = minimizer.SGD()\n",
    "sol=minim.train(mse(), M, np.transpose(X_train), np.transpose(Y_train), lr=0.01, maxiter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_train)))))\n",
    "\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On test set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_test)))))\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E(h|v) via SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 in 7.56(s), cost = 14.429409\n",
      "Iteration 100 in 815.80(s), cost = 2.250890\n",
      "Iteration 200 in 1624.00(s), cost = 1.968019\n",
      "Iteration 300 in 2411.39(s), cost = 1.823723\n",
      "Iteration 400 in 3112.41(s), cost = 1.744822\n",
      "Iteration 500 in 3891.12(s), cost = 1.699157\n",
      "Iteration 600 in 4684.85(s), cost = 1.669940\n",
      "Iteration 700 in 5463.40(s), cost = 1.648846\n",
      "Iteration 800 in 6207.63(s), cost = 1.632329\n",
      "Iteration 900 in 6944.76(s), cost = 1.618429\n",
      "('Cost: ', (1.6066652495271077+0j))\n",
      "('Sol: ', array([-1.11242407+0.j,  0.53777767+0.j,  0.91301536+0.j, ...,\n",
      "       -0.43379221+0.j, -0.86620570+0.j,  1.70059510+0.j]))\n",
      "Time: 7664 s\n"
     ]
    }
   ],
   "source": [
    "M = mdl.Model()\n",
    "M.add(layers.DiagExpectationUnitLayer(784,10))\n",
    "M.add(layers.DiagExpectationUnitLayer(10,1))\n",
    "\n",
    "minim = minimizer.SGD()\n",
    "sol=minim.train(mse(), M, np.transpose(X_train), np.transpose(Y_train),lr=0.1,momentum=0.5, nesterov=True,noise=1, maxiter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.20      0.32      1001\n",
      "        1.0       0.30      0.21      0.25      1127\n",
      "        2.0       0.19      0.25      0.22       991\n",
      "        3.0       0.25      0.32      0.28      1032\n",
      "        4.0       0.12      0.17      0.14       980\n",
      "        5.0       0.17      0.30      0.22       863\n",
      "        6.0       0.18      0.27      0.22      1014\n",
      "        7.0       0.29      0.31      0.30      1070\n",
      "        8.0       0.15      0.11      0.13       944\n",
      "        9.0       0.54      0.12      0.20       978\n",
      "       10.0       0.00      0.00      0.00         0\n",
      "       11.0       0.00      0.00      0.00         0\n",
      "       12.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.30      0.23      0.23     10000\n",
      "\n",
      "[[198 379 236 109  43  22  11   3   0   0   0   0   0]\n",
      " [  4 239 527 238  85  26   6   2   0   0   0   0   0]\n",
      " [ 32 113 244 303 179  85  29   5   1   0   0   0   0]\n",
      " [ 12  59 190 328 259 111  40  19  10   4   0   0   0]\n",
      " [  0   3  10  51 166 297 281 115  46  11   0   0   0]\n",
      " [  4   6  18 127 249 262 152  25  14   6   0   0   0]\n",
      " [  0   7  20  71 174 300 272 141  25   4   0   0   0]\n",
      " [  1   0   6  18  55 155 279 333 165  46  11   1   0]\n",
      " [  0   1   7  45 110 214 248 180 101  30   4   3   1]\n",
      " [  0   0   2   7  21  56 154 313 294 117  13   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_train)))))\n",
    "\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.76      0.19      0.30       980\n",
      "        1.0       0.29      0.20      0.24      1135\n",
      "        2.0       0.17      0.22      0.19      1032\n",
      "        3.0       0.24      0.30      0.27      1010\n",
      "        4.0       0.12      0.15      0.13       982\n",
      "        5.0       0.17      0.30      0.22       892\n",
      "        6.0       0.16      0.24      0.19       958\n",
      "        7.0       0.25      0.29      0.27      1028\n",
      "        8.0       0.17      0.12      0.14       974\n",
      "        9.0       0.47      0.09      0.15      1009\n",
      "       10.0       0.00      0.00      0.00         0\n",
      "       11.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.28      0.21      0.21     10000\n",
      "\n",
      "[[182 350 241 122  52  22   8   3   0   0   0   0]\n",
      " [  2 229 570 217  82  28   6   1   0   0   0   0]\n",
      " [ 38 140 227 289 193 113  24   6   1   0   1   0]\n",
      " [ 13  64 189 304 235 137  45  12  10   1   0   0]\n",
      " [  0   0   5  36 148 322 284 141  39   6   1   0]\n",
      " [  0   3  28 109 236 268 166  60  14   7   0   1]\n",
      " [  3   5  35  84 178 281 231 113  28   0   0   0]\n",
      " [  0   0   7  35  63 147 244 298 169  48  14   3]\n",
      " [  0   3   8  41  73 208 261 218 118  40   3   1]\n",
      " [  0   2   0  11  25  58 189 323 296  91  11   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# On test set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_test)))))\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E(h|v) via CMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = mdl.Model()\n",
    "M.add(layers.DiagExpectationUnitLayer(784,1))\n",
    "\n",
    "minim = minimizer.CMA(True)\n",
    "sol=minim.train(mse(), M, np.transpose(X_train), np.transpose(Y_train), maxiter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_train)))))\n",
    "\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On test set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_test)))))\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
