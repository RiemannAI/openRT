{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from rtbm.riemann_theta.riemann_theta import RiemannTheta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import theano\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Reshape  \n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import time\n",
    "\n",
    "from rtbm import RTBM, minimizer\n",
    "\n",
    "import rtbm.layers as layers\n",
    "import rtbm.model as mdl\n",
    "\n",
    "from rtbm.costfunctions import mse\n",
    "from rtbm.activations import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "MNIST_train = pd.read_csv('~/data/mnist_train.csv', delimiter=\",\",header=None).values\n",
    "MNIST_test  = pd.read_csv('~/data/mnist_test.csv', delimiter=\",\",header=None).values\n",
    "\n",
    "# Prepare data (normalized onto [0,1])\n",
    "Y_train = MNIST_train[0:10000,0]\n",
    "X_train = MNIST_train[0:10000,1:]/255.0\n",
    "\n",
    "Y_test = MNIST_test[:,0]\n",
    "X_test = MNIST_test[:,1:]/255.0\n",
    "\n",
    "enc = LabelBinarizer()\n",
    "enc.fit(np.diag([1,1,1,1,1,1,1,1,1,1]))\n",
    "enc.classes_ = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "T=enc.transform(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras (200 sigmoids + 10 sigmoids + 1 linear + MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Compile time: ', 0.005583000000001448)\n",
      "('Run time: ', 45.66247800000008)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Dense(200,  input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10,  input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(output_dim=1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.1)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.compile(loss='mse', optimizer=sgd)\n",
    "\n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Compile time: \",toc-tic)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=1000, nb_epoch=100, validation_data=None, shuffle=False, verbose=0)  \n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Run time: \",toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.65      0.78      1001\n",
      "          1       0.74      0.66      0.70      1127\n",
      "          2       0.52      0.44      0.48       991\n",
      "          3       0.50      0.51      0.51      1032\n",
      "          4       0.03      0.02      0.02       980\n",
      "          5       0.26      0.52      0.35       863\n",
      "          6       0.52      0.71      0.60      1014\n",
      "          7       0.47      0.36      0.40      1070\n",
      "          8       0.26      0.34      0.29       944\n",
      "          9       0.66      0.52      0.59       978\n",
      "\n",
      "avg / total       0.50      0.48      0.48     10000\n",
      "\n",
      "[[646 217  71  36  20   8   3   0   0   0]\n",
      " [  0 739 267  71  23  19   4   1   3   0]\n",
      " [  0  30 435 356  80  61  20   4   4   1]\n",
      " [  0   2  52 527 241 116  50  22  16   6]\n",
      " [  0   1   0   4  17 771 128  40  16   3]\n",
      " [  1   3  11  28  59 452 230  63  15   1]\n",
      " [  1   2   1   4  23 200 725  54   3   1]\n",
      " [  0   0   0  12  18  49  82 380 526   3]\n",
      " [  0   0   0  12  14  48 128 175 321 246]\n",
      " [  0   2   0   2   5   9  26  73 348 513]]\n"
     ]
    }
   ],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(model.predict(X_train)))).flatten()\n",
    "\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.62      0.77       980\n",
      "          1       0.73      0.66      0.70      1135\n",
      "          2       0.50      0.39      0.44      1032\n",
      "          3       0.46      0.50      0.48      1010\n",
      "          4       0.02      0.01      0.01       982\n",
      "          5       0.22      0.43      0.29       892\n",
      "          6       0.44      0.60      0.51       958\n",
      "          7       0.44      0.34      0.38      1028\n",
      "          8       0.26      0.33      0.29       974\n",
      "          9       0.62      0.50      0.56      1009\n",
      "\n",
      "avg / total       0.47      0.44      0.45     10000\n",
      "\n",
      "[[610 220  75  33  22  17   1   1   1   0]\n",
      " [  0 749 268  66  28  18   4   1   1   0]\n",
      " [  2  31 404 406  89  57  23  13   7   0]\n",
      " [  0   8  35 508 236 108  60  30  22   3]\n",
      " [  0   0   1   5   9 733 163  46  18   7]\n",
      " [  1   3  10  40  73 381 259  85  36   4]\n",
      " [  0   4   6  12  24 281 576  54   1   0]\n",
      " [  0   1   5  16  22  42  79 350 503  10]\n",
      " [  0   2   3   7  24  59 117 145 326 291]\n",
      " [  1   2   1   2   5  23  37  74 355 509]]\n"
     ]
    }
   ],
   "source": [
    "# On test set\n",
    "P=np.abs(np.round(np.real(model.predict(X_test)))).flatten()\n",
    "\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Theta and SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 in 0.39(s), cost = 4.186906\n",
      "Iteration 10 in 4.28(s), cost = 4.007818\n",
      "Iteration 20 in 8.17(s), cost = 2.072728\n",
      "Iteration 30 in 12.06(s), cost = 1.707744\n",
      "Iteration 40 in 15.95(s), cost = 1.607710\n",
      "Iteration 50 in 19.84(s), cost = 1.546584\n",
      "Iteration 60 in 23.73(s), cost = 1.499166\n",
      "Iteration 70 in 27.62(s), cost = 1.454172\n",
      "Iteration 80 in 31.51(s), cost = 1.403379\n",
      "Iteration 90 in 35.40(s), cost = 1.340367\n",
      "('Cost: ', 1.2735204231210209)\n",
      "('Sol: ', array([-0.04635235, -0.02339451, -0.05133954, ...,  0.97528025,\n",
      "        0.55323013,  1.55437903]))\n",
      "Time: 38 s\n"
     ]
    }
   ],
   "source": [
    "M = mdl.Model()\n",
    "M.add(layers.NonLinear(784,200,sigmoid()))\n",
    "M.add(layers.NonLinear(200,10,sigmoid()))\n",
    "M.add(layers.Linear(10,1))\n",
    "\n",
    "minim = minimizer.SGD()\n",
    "sol=minim.train(mse(), M, np.transpose(X_train), Y_train.reshape(1,len(Y_train)), lr=0.1, maxiter=100, batch_size=1000, log_step=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.24      0.38      1001\n",
      "          1       0.39      0.35      0.37      1127\n",
      "          2       0.26      0.31      0.28       991\n",
      "          3       0.34      0.32      0.33      1032\n",
      "          4       0.10      0.09      0.10       980\n",
      "          5       0.21      0.29      0.25       863\n",
      "          6       0.25      0.40      0.31      1014\n",
      "          7       0.23      0.37      0.28      1070\n",
      "          8       0.17      0.21      0.19       944\n",
      "          9       0.00      0.00      0.00       978\n",
      "\n",
      "avg / total       0.30      0.26      0.25     10000\n",
      "\n",
      "[[236 443 169  66  43  24  17   3   0   0]\n",
      " [  0 400 457 142  69  37  16   5   1   0]\n",
      " [  6 130 303 259 156  80  40  15   2   0]\n",
      " [  0  30 179 330 255 115  64  38  20   1]\n",
      " [  1   1   5  33  91 247 359 202  41   0]\n",
      " [  4   6  13  61 152 249 234 111  33   0]\n",
      " [  0   3   7  25  81 230 403 258   7   0]\n",
      " [  0   1   6  16  17  63 144 400 423   0]\n",
      " [  0   1   3  23  60 105 228 320 199   5]\n",
      " [  0   0   2   3  10  14  76 399 474   0]]\n"
     ]
    }
   ],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_train)))))\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.23      0.36       980\n",
      "          1       0.41      0.37      0.39      1135\n",
      "          2       0.25      0.28      0.26      1032\n",
      "          3       0.33      0.32      0.33      1010\n",
      "          4       0.10      0.09      0.09       982\n",
      "          5       0.20      0.25      0.22       892\n",
      "          6       0.23      0.38      0.29       958\n",
      "          7       0.20      0.36      0.26      1028\n",
      "          8       0.20      0.24      0.22       974\n",
      "          9       0.00      0.00      0.00      1009\n",
      "\n",
      "avg / total       0.29      0.25      0.24     10000\n",
      "\n",
      "[[221 413 188  79  37  20  17   4   1   0]\n",
      " [  0 418 449 149  61  34  18   5   1   0]\n",
      " [ 16 143 288 269 155  91  48  17   5   0]\n",
      " [  1  32 173 322 230 130  67  40  15   0]\n",
      " [  0   0   1  16  85 253 357 243  27   0]\n",
      " [  0   8  17  53 134 227 251 150  51   1]\n",
      " [  1   5  17  44  98 221 365 204   3   0]\n",
      " [  0   0  10  15  38  55 144 370 389   7]\n",
      " [  0   3   6  15  47  87 215 365 234   2]\n",
      " [  0   1   1   6   8  28  80 424 461   0]]\n"
     ]
    }
   ],
   "source": [
    "# On test set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_test)))))\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoftmaxKeras (200 sigmoids + 10 Softmax + MSE)Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Compile time: ', 0.004078000000163229)\n",
      "('Run time: ', 45.71273099999985)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Dense(200,  input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10,  input_dim=784))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.1)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.compile(loss='mse', optimizer=sgd)\n",
    "\n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Compile time: \",toc-tic)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.fit(X_train, T, batch_size=1000, nb_epoch=100, validation_data=None, shuffle=False, verbose=0)  \n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Run time: \",toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.97      0.63      1001\n",
      "          1       0.46      0.98      0.63      1127\n",
      "          2       0.88      0.49      0.63       991\n",
      "          3       0.73      0.45      0.56      1032\n",
      "          4       0.83      0.53      0.65       980\n",
      "          5       0.00      0.00      0.00       863\n",
      "          6       0.74      0.72      0.73      1014\n",
      "          7       0.37      0.94      0.53      1070\n",
      "          8       1.00      0.01      0.03       944\n",
      "          9       0.00      0.00      0.00       978\n",
      "\n",
      "avg / total       0.55      0.53      0.45     10000\n",
      "\n",
      "[[ 973    8    2    1    1    0    8    8    0    0]\n",
      " [   1 1107    3    1    0    0    0   15    0    0]\n",
      " [  82  227  490   21   14    0   77   80    0    0]\n",
      " [ 189  178   18  464    3    0   11  169    0    0]\n",
      " [  59   40    2    5  520    0   40  314    0    0]\n",
      " [ 356  252    1   33    7    0   51  163    0    0]\n",
      " [ 116  109    8    1   15    0  735   30    0    0]\n",
      " [  30   29    4    0    4    0    1 1002    0    0]\n",
      " [ 173  427   27   99   36    0   66  103   13    0]\n",
      " [  88   35    0    7   26    0    8  814    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# On train set\n",
    "P=np.argmax(model.predict(X_train),axis=1)\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.98      0.61       980\n",
      "          1       0.50      0.99      0.66      1135\n",
      "          2       0.89      0.47      0.62      1032\n",
      "          3       0.73      0.48      0.58      1010\n",
      "          4       0.80      0.50      0.61       982\n",
      "          5       0.00      0.00      0.00       892\n",
      "          6       0.72      0.69      0.71       958\n",
      "          7       0.34      0.93      0.50      1028\n",
      "          8       1.00      0.03      0.05       974\n",
      "          9       0.00      0.00      0.00      1009\n",
      "\n",
      "avg / total       0.55      0.52      0.44     10000\n",
      "\n",
      "[[ 963    6    1    0    0    0    3    7    0    0]\n",
      " [   1 1124    2    1    0    0    0    7    0    0]\n",
      " [  95  265  487   31   10    0   49   95    0    0]\n",
      " [ 200  151   13  487    0    0   21  138    0    0]\n",
      " [  58   36    1    5  489    0   48  345    0    0]\n",
      " [ 436  194    4   21   15    0   42  179    0    1]\n",
      " [ 158   72    8    1   23    0  663   33    0    0]\n",
      " [  13   48    9    0    2    0    0  956    0    0]\n",
      " [ 159  332   14  118   39    0   81  206   25    0]\n",
      " [  89   31    6    4   34    0   12  833    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# On test set\n",
    "P=np.argmax(model.predict(X_test),axis=1)\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 in 0.41(s), cost = 0.449818\n",
      "Iteration 10 in 4.49(s), cost = 0.449799\n",
      "Iteration 20 in 8.58(s), cost = 0.449759\n",
      "Iteration 30 in 12.67(s), cost = 0.449722\n",
      "Iteration 40 in 16.75(s), cost = 0.449676\n",
      "Iteration 50 in 20.84(s), cost = 0.449616\n",
      "Iteration 60 in 24.94(s), cost = 0.449547\n",
      "Iteration 70 in 29.02(s), cost = 0.449488\n",
      "Iteration 80 in 33.11(s), cost = 0.449472\n",
      "Iteration 90 in 37.20(s), cost = 0.449502\n",
      "('Cost: ', 0.44954842310257515)\n",
      "('Sol: ', array([ 0.04898311,  0.04930198,  0.04964121, ..., -0.20971305,\n",
      "       -0.20161145, -0.19696665]))\n",
      "Time: 40 s\n"
     ]
    }
   ],
   "source": [
    "M = mdl.Model()\n",
    "M.add(layers.NonLinear(784,200,sigmoid()))\n",
    "M.add(layers.Linear(200,10))\n",
    "M.add(layers.SoftMaxLayer(10))\n",
    "\n",
    "minim = minimizer.SGD()\n",
    "sol=minim.train(mse(), M, np.transpose(X_train), T.T, lr=0.1, maxiter=100, batch_size=1000, log_step=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
