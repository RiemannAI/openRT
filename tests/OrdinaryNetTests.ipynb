{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from rtbm.riemann_theta.riemann_theta import RiemannTheta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import theano\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Reshape  \n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import time\n",
    "\n",
    "from rtbm import RTBM, minimizer\n",
    "\n",
    "import rtbm.layers as layers\n",
    "import rtbm.model as mdl\n",
    "\n",
    "from rtbm.costfunctions import mse\n",
    "from rtbm.activations import sigmoid, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "MNIST_train = pd.read_csv('~/data/mnist_train.csv', delimiter=\",\",header=None).values\n",
    "MNIST_test  = pd.read_csv('~/data/mnist_test.csv', delimiter=\",\",header=None).values\n",
    "\n",
    "# Prepare data (normalized onto [0,1])\n",
    "Y_train = MNIST_train[0:10000,0]\n",
    "X_train = MNIST_train[0:10000,1:]/255.0\n",
    "\n",
    "Y_test = MNIST_test[:,0]\n",
    "X_test = MNIST_test[:,1:]/255.0\n",
    "\n",
    "enc = LabelBinarizer()\n",
    "enc.fit(np.diag([1,1,1,1,1,1,1,1,1,1]))\n",
    "enc.classes_ = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "T=enc.transform(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras (500 linear + 100 linear + 1 linear + MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Dense(500,  input_dim=784))\n",
    "model.add(Activation('linear'))\n",
    "#model.add(Dense(100,  input_dim=784))\n",
    "#model.add(Activation('linear'))\n",
    "model.add(Dense(output_dim=1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.001)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.compile(loss='mse', optimizer=sgd)\n",
    "\n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Compile time: \",toc-tic)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=10000, nb_epoch=100, validation_data=None, shuffle=False, verbose=1)  \n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Run time: \",toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(model.predict(X_train)))).flatten()\n",
    "\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On test set\n",
    "P=np.abs(np.round(np.real(model.predict(X_test)))).flatten()\n",
    "\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Theta and SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Batch C: ', 26.949287783655517)\n",
      "Iteration 0 in 0.49(s), cost = 19.760788\n",
      "('Batch C: ', 7.6847045878354505)\n",
      "Iteration 10 in 3.63(s), cost = 7.536740\n",
      "('Batch C: ', 6.691516365115832)\n",
      "Iteration 20 in 6.71(s), cost = 6.619935\n",
      "('Batch C: ', 6.0888996304586165)\n",
      "Iteration 30 in 9.77(s), cost = 6.040583\n",
      "('Batch C: ', 5.6793073799621965)\n",
      "Iteration 40 in 12.82(s), cost = 5.646176\n",
      "('Batch C: ', 5.396317650266337)\n",
      "Iteration 50 in 15.89(s), cost = 5.373155\n",
      "('Batch C: ', 5.196349806893555)\n",
      "Iteration 60 in 18.95(s), cost = 5.179716\n",
      "('Batch C: ', 5.050745746312988)\n",
      "Iteration 70 in 22.00(s), cost = 5.038390\n",
      "('Batch C: ', 4.940835938722546)\n",
      "Iteration 80 in 25.05(s), cost = 4.931301\n",
      "('Batch C: ', 4.854576459623521)\n",
      "Iteration 90 in 28.10(s), cost = 4.846926\n",
      "('Cost: ', 4.7907242554340375)\n",
      "('Sol: ', array([0.00214954, 0.00696797, 0.00887331, ..., 0.05668997, 0.00395233,\n",
      "       0.08101485]))\n",
      "Time: 30 s\n"
     ]
    }
   ],
   "source": [
    "M = mdl.Model()\n",
    "M.add(layers.NonLinear(784,500,linear()))\n",
    "#M.add(layers.NonLinear(500,100,linear()))\n",
    "M.add(layers.NonLinear(500,1,linear()))\n",
    "\n",
    "minim = minimizer.SGD()\n",
    "sol=minim.train(mse(), M, np.transpose(X_train), Y_train.reshape(1,len(Y_train)), lr=0.001, maxiter=100, batch_size=10000, log_step=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.14      0.25      1001\n",
      "        1.0       0.22      0.12      0.15      1127\n",
      "        2.0       0.16      0.21      0.18       991\n",
      "        3.0       0.18      0.29      0.22      1032\n",
      "        4.0       0.09      0.16      0.11       980\n",
      "        5.0       0.09      0.17      0.12       863\n",
      "        6.0       0.10      0.13      0.11      1014\n",
      "        7.0       0.26      0.21      0.23      1070\n",
      "        8.0       0.15      0.06      0.09       944\n",
      "        9.0       0.47      0.07      0.13       978\n",
      "       10.0       0.00      0.00      0.00         0\n",
      "       11.0       0.00      0.00      0.00         0\n",
      "       12.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.26      0.16      0.16     10000\n",
      "\n",
      "[[144 319 244 130  89  42  17  12   4   0   0   0   0]\n",
      " [  0 131 464 333 133  50  11   3   2   0   0   0   0]\n",
      " [ 13  74 207 302 214 123  44  12   2   0   0   0   0]\n",
      " [  3  40 196 295 251 148  62  21  13   1   2   0   0]\n",
      " [  1   5  16  69 158 287 245 131  55  11   2   0   0]\n",
      " [  1  22 124 217 252 147  66  27   6   1   0   0   0]\n",
      " [  0   6  49 168 340 245 132  55  15   4   0   0   0]\n",
      " [  1   3  12  61 135 233 272 224  93  32   4   0   0]\n",
      " [  0   0  12  77 197 230 190 136  60  31   9   1   1]\n",
      " [  0   4   5  18  66 130 259 244 155  71  23   3   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_train)))))\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.14      0.25      1001\n",
      "        1.0       0.22      0.12      0.15      1127\n",
      "        2.0       0.16      0.21      0.18       991\n",
      "        3.0       0.18      0.29      0.22      1032\n",
      "        4.0       0.09      0.16      0.11       980\n",
      "        5.0       0.09      0.17      0.12       863\n",
      "        6.0       0.10      0.13      0.11      1014\n",
      "        7.0       0.26      0.21      0.23      1070\n",
      "        8.0       0.15      0.06      0.09       944\n",
      "        9.0       0.47      0.07      0.13       978\n",
      "       10.0       0.00      0.00      0.00         0\n",
      "       11.0       0.00      0.00      0.00         0\n",
      "       12.0       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.26      0.16      0.16     10000\n",
      "\n",
      "[[144 319 244 130  89  42  17  12   4   0   0   0   0]\n",
      " [  0 131 464 333 133  50  11   3   2   0   0   0   0]\n",
      " [ 13  74 207 302 214 123  44  12   2   0   0   0   0]\n",
      " [  3  40 196 295 251 148  62  21  13   1   2   0   0]\n",
      " [  1   5  16  69 158 287 245 131  55  11   2   0   0]\n",
      " [  1  22 124 217 252 147  66  27   6   1   0   0   0]\n",
      " [  0   6  49 168 340 245 132  55  15   4   0   0   0]\n",
      " [  1   3  12  61 135 233 272 224  93  32   4   0   0]\n",
      " [  0   0  12  77 197 230 190 136  60  31   9   1   1]\n",
      " [  0   4   5  18  66 130 259 244 155  71  23   3   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_train)))))\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras (200 sigmoids + 10 sigmoids + 1 linear + MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Compile time: ', 0.003959000000008928)\n",
      "('Run time: ', 43.429708000000005)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Dense(10,  input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "#model.add(Dense(10))\n",
    "#model.add(Activation('sigmoid'))\n",
    "model.add(Dense(output_dim=1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.1)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.compile(loss='mse', optimizer=sgd)\n",
    "\n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Compile time: \",toc-tic)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=10000, nb_epoch=200, validation_data=None, shuffle=False, verbose=0)  \n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Run time: \",toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.47      0.62      1001\n",
      "          1       0.62      0.54      0.58      1127\n",
      "          2       0.40      0.60      0.48       991\n",
      "          3       0.38      0.30      0.34      1032\n",
      "          4       0.03      0.02      0.03       980\n",
      "          5       0.20      0.54      0.29       863\n",
      "          6       0.11      0.12      0.12      1014\n",
      "          7       0.35      0.27      0.31      1070\n",
      "          8       0.17      0.25      0.20       944\n",
      "          9       0.00      0.00      0.00       978\n",
      "\n",
      "avg / total       0.33      0.31      0.30     10000\n",
      "\n",
      "[[466 302 125  49  36  16   6   1   0   0]\n",
      " [ 38 606 275 122  56  20   8   2   0   0]\n",
      " [  1  51 591 189  79  60  14   6   0   0]\n",
      " [  1   8 430 311 112 101  40  13  16   0]\n",
      " [  0   1   0   9  21 571 323  44  11   0]\n",
      " [  5   4  36  60 133 464 100  43  18   0]\n",
      " [  0   3   5  20  86 770 121   8   1   0]\n",
      " [  0   1   7  18  40 105 192 290 417   0]\n",
      " [  0   0  11  31  69 189 200 212 232   0]\n",
      " [  0   1   2   8   9  23  84 212 639   0]]\n"
     ]
    }
   ],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(model.predict(X_train)))).flatten()\n",
    "\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.45      0.61       980\n",
      "          1       0.61      0.55      0.58      1135\n",
      "          2       0.40      0.59      0.48      1032\n",
      "          3       0.34      0.27      0.30      1010\n",
      "          4       0.03      0.02      0.02       982\n",
      "          5       0.18      0.46      0.26       892\n",
      "          6       0.07      0.08      0.07       958\n",
      "          7       0.33      0.27      0.30      1028\n",
      "          8       0.21      0.29      0.24       974\n",
      "          9       0.00      0.00      0.00      1009\n",
      "\n",
      "avg / total       0.32      0.30      0.29     10000\n",
      "\n",
      "[[439 297 134  63  25  15   5   1   1   0]\n",
      " [ 23 625 294 115  32  41   4   1   0   0]\n",
      " [  2  61 610 193  78  58  22   5   3   0]\n",
      " [  1  17 408 272 132 105  40  23  12   0]\n",
      " [  0   0   0   6  20 551 346  47  12   0]\n",
      " [  2  12  46  48 158 410 125  62  29   0]\n",
      " [  1   5  12  38  86 733  77   6   0   0]\n",
      " [  0   2  11  24  47  97 171 276 400   0]\n",
      " [  0   3  11  26  53 183 224 192 282   0]\n",
      " [  0   2   4   6   9  42  97 221 628   0]]\n"
     ]
    }
   ],
   "source": [
    "# On test set\n",
    "P=np.abs(np.round(np.real(model.predict(X_test)))).flatten()\n",
    "\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Theta and SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Batch C: ', 31.87743043119631)\n",
      "Iteration 0 in 0.06(s), cost = 8.117631\n",
      "('Batch C: ', 6.057554959999378)\n",
      "Iteration 10 in 0.54(s), cost = 5.860846\n",
      "('Batch C: ', 4.612933130291003)\n",
      "Iteration 20 in 1.02(s), cost = 4.520134\n",
      "('Batch C: ', 3.936395437084709)\n",
      "Iteration 30 in 1.50(s), cost = 3.891226\n",
      "('Batch C: ', 3.7096171514261966)\n",
      "Iteration 40 in 1.98(s), cost = 3.777202\n",
      "('Batch C: ', 4.234339501213176)\n",
      "Iteration 50 in 2.46(s), cost = 3.894293\n",
      "('Batch C: ', 3.3857447499345703)\n",
      "Iteration 60 in 2.93(s), cost = 3.368551\n",
      "('Batch C: ', 3.235045523283662)\n",
      "Iteration 70 in 3.41(s), cost = 3.221552\n",
      "('Batch C: ', 3.1083328177461995)\n",
      "Iteration 80 in 3.89(s), cost = 3.096569\n",
      "('Batch C: ', 2.9972193636453244)\n",
      "Iteration 90 in 4.34(s), cost = 2.986890\n",
      "('Batch C: ', 2.9012325880601773)\n",
      "Iteration 100 in 4.75(s), cost = 2.892743\n",
      "('Batch C: ', 2.8367884411591033)\n",
      "Iteration 110 in 5.18(s), cost = 2.834637\n",
      "('Batch C: ', 2.898089346268338)\n",
      "Iteration 120 in 5.59(s), cost = 2.913072\n",
      "('Batch C: ', 2.9041095367169247)\n",
      "Iteration 130 in 6.01(s), cost = 2.878167\n",
      "('Batch C: ', 2.6833480521327004)\n",
      "Iteration 140 in 6.43(s), cost = 2.667475\n",
      "('Batch C: ', 2.5722054800160548)\n",
      "Iteration 150 in 6.85(s), cost = 2.564230\n",
      "('Batch C: ', 2.5060949011053477)\n",
      "Iteration 160 in 7.27(s), cost = 2.500452\n",
      "('Batch C: ', 2.4555783775519715)\n",
      "Iteration 170 in 7.69(s), cost = 2.450985\n",
      "('Batch C: ', 2.41360994569833)\n",
      "Iteration 180 in 8.11(s), cost = 2.409722\n",
      "('Batch C: ', 2.378195500597413)\n",
      "Iteration 190 in 8.53(s), cost = 2.374886\n",
      "('Cost: ', 2.3510282976614354)\n",
      "('Sol: ', array([-0.04734393, -0.01414296, -0.10033281, ...,  2.39549968,\n",
      "        2.64733974,  0.27058659]))\n",
      "Time: 8 s\n"
     ]
    }
   ],
   "source": [
    "M = mdl.Model()\n",
    "M.add(layers.NonLinear(784,10,sigmoid()))\n",
    "#M.add(layers.NonLinear(200,10,sigmoid()))\n",
    "M.add(layers.Linear(10,1))\n",
    "\n",
    "minim = minimizer.SGD()\n",
    "sol=minim.train(mse(), M, np.transpose(X_train), Y_train.reshape(1,len(Y_train)), lr=0.1, maxiter=200, batch_size=10000, log_step=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.49      0.64      1001\n",
      "          1       0.48      0.54      0.51      1127\n",
      "          2       0.37      0.35      0.36       991\n",
      "          3       0.50      0.58      0.54      1032\n",
      "          4       0.16      0.15      0.15       980\n",
      "          5       0.21      0.36      0.27       863\n",
      "          6       0.28      0.46      0.35      1014\n",
      "          7       0.37      0.34      0.35      1070\n",
      "          8       0.16      0.18      0.17       944\n",
      "          9       0.00      0.00      0.00       978\n",
      "\n",
      "avg / total       0.35      0.35      0.34     10000\n",
      "\n",
      "[[490 307 102  46  33  15   8   0   0   0]\n",
      " [ 22 607 309 107  55  16  11   0   0   0]\n",
      " [  2 287 348 199  85  45  19   6   0   0]\n",
      " [  1  34 121 601 129  80  39  13  14   0]\n",
      " [  0   1   3  23 143 330 426  46   8   0]\n",
      " [  4   8  20 118 203 313 151  35  11   0]\n",
      " [  1   3  10  29 108 394 467   2   0   0]\n",
      " [  0   2   6  23  45  91 198 361 344   0]\n",
      " [  0   2  12  40  81 162 262 212 173   0]\n",
      " [  0   1   3  10  11  23 112 307 511   0]]\n"
     ]
    }
   ],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_train)))))\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.46      0.62       980\n",
      "          1       0.50      0.56      0.52      1135\n",
      "          2       0.37      0.36      0.36      1032\n",
      "          3       0.48      0.56      0.52      1010\n",
      "          4       0.15      0.13      0.14       982\n",
      "          5       0.22      0.33      0.26       892\n",
      "          6       0.25      0.47      0.33       958\n",
      "          7       0.32      0.32      0.32      1028\n",
      "          8       0.18      0.19      0.19       974\n",
      "          9       0.00      0.00      0.00      1009\n",
      "\n",
      "avg / total       0.34      0.34      0.33     10000\n",
      "\n",
      "[[452 307 124  46  27  17   6   1   0   0]\n",
      " [ 18 631 298 117  36  30   4   1   0   0]\n",
      " [  6 286 369 198  95  43  28   5   2   0]\n",
      " [  2  24 130 567 151  77  32  21   6   0]\n",
      " [  0   0   2  12 127 314 471  49   7   0]\n",
      " [  0  11  20 118 204 296 169  61  13   0]\n",
      " [  0   6  23  48 105 329 446   1   0   0]\n",
      " [  0   3  13  31  48  83 179 334 337   0]\n",
      " [  0   5   9  32  68 119 324 229 188   0]\n",
      " [  0   1   4   9  11  46 111 334 493   0]]\n"
     ]
    }
   ],
   "source": [
    "# On test set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_test)))))\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoftmaxKeras (200 sigmoids + 10 Softmax + MSE)Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Dense(200,  input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10,  input_dim=784))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.1)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.compile(loss='mse', optimizer=sgd)\n",
    "\n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Compile time: \",toc-tic)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.fit(X_train, T, batch_size=1000, nb_epoch=100, validation_data=None, shuffle=False, verbose=0)  \n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Run time: \",toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "P=np.argmax(model.predict(X_train),axis=1)\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On test set\n",
    "P=np.argmax(model.predict(X_test),axis=1)\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = mdl.Model()\n",
    "M.add(layers.NonLinear(784,200,sigmoid()))\n",
    "M.add(layers.Linear(200,10))\n",
    "M.add(layers.SoftMaxLayer(10))\n",
    "\n",
    "minim = minimizer.SGD()\n",
    "sol=minim.train(mse(), M, np.transpose(X_train), T.T, lr=0.1, maxiter=100, batch_size=1000, log_step=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
